{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from vec_db import VecDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################################\n",
    "############################################################ HYPER PARAMETERS ######################################################################\n",
    "####################################################################################################################################################\n",
    "\n",
    "# vector dimension\n",
    "dimension = 70 \n",
    "\n",
    "# number of subvectors for each vector\n",
    "no_of_subspaces = 14\n",
    "assert dimension % no_of_subspaces == 0, \"Dimension must be divisible by number of subspaces\"\n",
    "\n",
    "# number of clusters for kmeans to build the codebook\n",
    "no_of_clusters = 8\n",
    "\n",
    "# how many similar vectors to search for\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data to subspaces \n",
    "def get_subspaces(data, no_of_subspaces : int):\n",
    "    data = np.array(data)\n",
    "    if data.ndim == 1: # just 1 vector\n",
    "        data = np.array(data).reshape(1, -1) # so i can use np.split() lol\n",
    "    return np.array(np.split(data, no_of_subspaces, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2]\n",
      "  [ 1  2]]\n",
      "\n",
      " [[ 3  4]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 5  6]]\n",
      "\n",
      " [[ 7  8]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [ 9 10]]\n",
      "\n",
      " [[11 12]\n",
      "  [11 12]]\n",
      "\n",
      " [[13 14]\n",
      "  [13 14]]]\n"
     ]
    }
   ],
   "source": [
    "print(get_subspaces([[1,2,3,4,5,6,7,8,9,10,11,12,13,14], [1,2,3,4,5,6,7,8,9,10,11,12,13,14]], 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the codebooks that maps each subvector to a centroid\n",
    "def generate_code_books(training_data, no_of_subspaces, no_of_clusters):\n",
    "    codebooks = []\n",
    "    subspaces = get_subspaces(training_data, no_of_subspaces)\n",
    "    for subspace in subspaces:\n",
    "        # Kmeans estimator to train on each supspace\n",
    "        kmeans = KMeans(n_clusters=no_of_clusters, random_state=42) ###### TODO: may change this #######\n",
    "        kmeans.fit(subspace)\n",
    "        # Kmeans centers are our codebook for each supspace\n",
    "        codebooks.append(kmeans.cluster_centers_)\n",
    "    return np.array(codebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 8, 5)\n",
      "[[[0.44997337 0.23269832 0.31560433 0.47591147 0.80642354]\n",
      "  [0.25576827 0.38199094 0.68817246 0.194339   0.45338392]\n",
      "  [0.7806767  0.7228936  0.48222357 0.22787589 0.4391714 ]\n",
      "  [0.57021344 0.29064944 0.20719227 0.6307481  0.26467365]\n",
      "  [0.36705002 0.75684595 0.64821076 0.69584465 0.260467  ]\n",
      "  [0.5656305  0.20001897 0.7403931  0.67763793 0.29954308]\n",
      "  [0.53125453 0.6497312  0.71436465 0.67211676 0.79902136]\n",
      "  [0.33950537 0.7824727  0.18098754 0.52840513 0.64107096]]\n",
      "\n",
      " [[0.22232088 0.21563518 0.6230648  0.5331292  0.33474505]\n",
      "  [0.7699231  0.73689604 0.36544937 0.6897883  0.7249875 ]\n",
      "  [0.26257676 0.61358494 0.38697627 0.28121006 0.7706114 ]\n",
      "  [0.6958831  0.25548187 0.30443084 0.71339434 0.256062  ]\n",
      "  [0.6012192  0.59827673 0.19334742 0.25121728 0.26618803]\n",
      "  [0.54997844 0.2621142  0.664062   0.5924695  0.8196309 ]\n",
      "  [0.7316949  0.58469224 0.7565475  0.26722866 0.38648966]\n",
      "  [0.28978676 0.7960354  0.45560753 0.7337221  0.30159292]]\n",
      "\n",
      " [[0.26694593 0.5889511  0.23770209 0.3371842  0.73706955]\n",
      "  [0.28225917 0.22269088 0.33894697 0.7309748  0.38470012]\n",
      "  [0.7526368  0.2555238  0.7328781  0.4815377  0.3770517 ]\n",
      "  [0.3427564  0.7859359  0.5192827  0.75597715 0.31784323]\n",
      "  [0.24543375 0.37201902 0.6729363  0.18322557 0.44648442]\n",
      "  [0.7574967  0.67830867 0.30972773 0.37072542 0.2425254 ]\n",
      "  [0.7818866  0.3168912  0.24579163 0.55575    0.7689566 ]\n",
      "  [0.5654765  0.6987979  0.779216   0.56022793 0.7811463 ]]\n",
      "\n",
      " [[0.26370442 0.4808397  0.75332177 0.39547592 0.26972198]\n",
      "  [0.56876355 0.7436874  0.33819354 0.7986214  0.31263763]\n",
      "  [0.226553   0.3022511  0.29876077 0.7100913  0.6582438 ]\n",
      "  [0.5402044  0.7811489  0.7193718  0.47012937 0.7498673 ]\n",
      "  [0.7627071  0.2875542  0.3875841  0.31916374 0.24403012]\n",
      "  [0.34434107 0.7177808  0.24487264 0.23580647 0.34259945]\n",
      "  [0.62752503 0.33697262 0.2733177  0.25958878 0.7869403 ]\n",
      "  [0.70140046 0.27566227 0.70616364 0.730266   0.5901754 ]]\n",
      "\n",
      " [[0.7002566  0.29865435 0.3479002  0.27753645 0.6819866 ]\n",
      "  [0.60095686 0.7772108  0.19340685 0.43115485 0.33340132]\n",
      "  [0.73181564 0.5355315  0.7420231  0.7856617  0.4466549 ]\n",
      "  [0.7076175  0.5205181  0.7473521  0.23578542 0.29738706]\n",
      "  [0.42946628 0.5088697  0.22985756 0.80205727 0.70985657]\n",
      "  [0.31774983 0.2408691  0.35401928 0.5586382  0.21494487]\n",
      "  [0.22393987 0.78633404 0.6622349  0.45138964 0.52877754]\n",
      "  [0.20738879 0.22544467 0.7415553  0.43598744 0.6665063 ]]\n",
      "\n",
      " [[0.21262449 0.18617079 0.56399137 0.3932112  0.37129375]\n",
      "  [0.71509683 0.57023174 0.29999042 0.21028674 0.6453028 ]\n",
      "  [0.63418186 0.3220649  0.23318547 0.6416813  0.26797193]\n",
      "  [0.77604365 0.46553734 0.79866815 0.39715335 0.27841145]\n",
      "  [0.70805645 0.47933322 0.54772985 0.78862214 0.7301621 ]\n",
      "  [0.19757277 0.5921436  0.2016432  0.46943533 0.72741413]\n",
      "  [0.31743383 0.77769935 0.54331064 0.5535587  0.24675605]\n",
      "  [0.365475   0.60639554 0.7920008  0.41462806 0.777128  ]]\n",
      "\n",
      " [[0.41929555 0.7202102  0.21988356 0.7683808  0.56657106]\n",
      "  [0.242403   0.74797136 0.66206366 0.31970948 0.28416443]\n",
      "  [0.7681761  0.24150693 0.26430476 0.43829742 0.62415326]\n",
      "  [0.26084477 0.36273456 0.55922854 0.23786253 0.7419951 ]\n",
      "  [0.30743974 0.23716119 0.33768737 0.663476   0.265158  ]\n",
      "  [0.623302   0.6191946  0.7352256  0.7572384  0.74713904]\n",
      "  [0.700318   0.42097196 0.7992317  0.5210002  0.2568011 ]\n",
      "  [0.7123493  0.7583473  0.29524562 0.25316727 0.4553464 ]]\n",
      "\n",
      " [[0.6670987  0.24396819 0.7572906  0.64681196 0.3040682 ]\n",
      "  [0.61425024 0.37264907 0.37867928 0.71890414 0.8258918 ]\n",
      "  [0.6384473  0.478558   0.27928746 0.27369297 0.24116361]\n",
      "  [0.22557092 0.44922936 0.78946865 0.27602288 0.45829362]\n",
      "  [0.19160905 0.56757313 0.26996535 0.38190806 0.74763405]\n",
      "  [0.77866673 0.6346573  0.62674224 0.2685573  0.7345636 ]\n",
      "  [0.4438677  0.7960923  0.66829056 0.7400173  0.4044757 ]\n",
      "  [0.32827628 0.4407394  0.18613225 0.8045349  0.3376735 ]]\n",
      "\n",
      " [[0.7343809  0.43440196 0.62099516 0.18427718 0.7827649 ]\n",
      "  [0.556594   0.73255694 0.7864538  0.67608374 0.27896857]\n",
      "  [0.69380414 0.5979837  0.30179182 0.27818754 0.30794898]\n",
      "  [0.22904307 0.48933986 0.19048297 0.36343262 0.6042789 ]\n",
      "  [0.3070569  0.20310056 0.70278597 0.46642354 0.3204174 ]\n",
      "  [0.733095   0.42127478 0.44886294 0.7728808  0.748595  ]\n",
      "  [0.21304893 0.7119796  0.7009882  0.5091655  0.737007  ]\n",
      "  [0.45387843 0.49926808 0.22216687 0.79768336 0.277167  ]]\n",
      "\n",
      " [[0.21968576 0.725543   0.4558944  0.492988   0.21326989]\n",
      "  [0.76429987 0.65509075 0.7820325  0.72427917 0.43299404]\n",
      "  [0.37600046 0.71203476 0.3651845  0.24631727 0.78045017]\n",
      "  [0.62150496 0.37509498 0.79450524 0.23421493 0.6704745 ]\n",
      "  [0.31936342 0.19381315 0.65053093 0.549581   0.30335915]\n",
      "  [0.29364473 0.57004136 0.54782975 0.7850373  0.7461905 ]\n",
      "  [0.76865596 0.661564   0.2546243  0.3666591  0.31636667]\n",
      "  [0.6064962  0.24316347 0.19488516 0.6097941  0.6154353 ]]\n",
      "\n",
      " [[0.5649264  0.7894981  0.74332714 0.58507824 0.28675967]\n",
      "  [0.5245783  0.7270218  0.285448   0.77111506 0.6636739 ]\n",
      "  [0.27772576 0.59940755 0.18718812 0.30220577 0.3804536 ]\n",
      "  [0.5359554  0.27949625 0.77402323 0.24252737 0.2636073 ]\n",
      "  [0.2585358  0.22816908 0.5943561  0.75892085 0.50152767]\n",
      "  [0.7996168  0.4075228  0.5553384  0.39622363 0.79029727]\n",
      "  [0.7647741  0.26317656 0.33937585 0.6349591  0.2856203 ]\n",
      "  [0.26982796 0.68184865 0.669577   0.32825014 0.765355  ]]\n",
      "\n",
      " [[0.7585226  0.45265955 0.5492696  0.81080085 0.6889266 ]\n",
      "  [0.48458377 0.62947553 0.21173644 0.51120436 0.21614349]\n",
      "  [0.22189167 0.57204217 0.56529164 0.79819155 0.71469444]\n",
      "  [0.7774974  0.6837533  0.54396844 0.24395049 0.69935215]\n",
      "  [0.585936   0.19108996 0.18290046 0.4245833  0.5734751 ]\n",
      "  [0.18359232 0.67722136 0.37535414 0.21977639 0.673713  ]\n",
      "  [0.45850497 0.19175684 0.72705156 0.3405124  0.42814085]\n",
      "  [0.3988403  0.695904   0.747185   0.6787186  0.1948866 ]]\n",
      "\n",
      " [[0.7630539  0.22124022 0.5414845  0.3612712  0.25822973]\n",
      "  [0.5684028  0.7758993  0.5525822  0.27269465 0.25728858]\n",
      "  [0.57313734 0.7774813  0.6382267  0.8102383  0.36878976]\n",
      "  [0.7204495  0.36959085 0.7169184  0.47616425 0.7994071 ]\n",
      "  [0.71065116 0.622419   0.18228939 0.569432   0.6582928 ]\n",
      "  [0.21883735 0.56264365 0.6509565  0.32011878 0.77030444]\n",
      "  [0.24050125 0.29959923 0.47039455 0.8069012  0.4803913 ]\n",
      "  [0.27223122 0.35703203 0.22504103 0.29892987 0.3071767 ]]\n",
      "\n",
      " [[0.5897474  0.7496412  0.7689317  0.41317362 0.7809651 ]\n",
      "  [0.681823   0.66674256 0.24124855 0.7907549  0.5200013 ]\n",
      "  [0.38871986 0.20342049 0.28419033 0.44825155 0.27073887]\n",
      "  [0.26412082 0.64873505 0.70181954 0.73347855 0.2780307 ]\n",
      "  [0.77315116 0.5593979  0.68267834 0.3659252  0.22831565]\n",
      "  [0.7808709  0.33400434 0.3230833  0.3474287  0.76458097]\n",
      "  [0.26813763 0.727139   0.37863684 0.21322781 0.4771893 ]\n",
      "  [0.34139106 0.26048175 0.628933   0.6977181  0.72082657]]]\n"
     ]
    }
   ],
   "source": [
    "db = VecDB(db_size=1000)\n",
    "codebook = generate_code_books(db.get_all_rows(), no_of_subspaces, no_of_clusters)\n",
    "print(codebook.shape)\n",
    "print(codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode our database vectors (convert every vector to its centroids)\n",
    "def encode_data(data, codebook, no_of_subspaces):\n",
    "    subspaces = get_subspaces(data, no_of_subspaces)\n",
    "    encoded_data = []\n",
    "    for i in range(0, no_of_subspaces):\n",
    "        encoded_supspace = []\n",
    "        # for each supspace\n",
    "        for subvector in subspaces[i]:\n",
    "            # find nearest centroid in the codebook for this supspace\n",
    "            encoded_supspace.append(np.argmin([np.linalg.norm(subvector - codeword) for codeword in codebook[i]]))\n",
    "        encoded_data.append(encoded_supspace)\n",
    "    return np.array(encoded_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 14)\n",
      "[[4 6 7 ... 2 2 6]\n",
      " [0 5 6 ... 6 4 6]\n",
      " [0 3 2 ... 5 2 0]\n",
      " ...\n",
      " [2 3 0 ... 2 3 1]\n",
      " [0 0 7 ... 4 3 5]\n",
      " [6 3 3 ... 5 4 6]]\n"
     ]
    }
   ],
   "source": [
    "encoded_data = encode_data(db.get_all_rows(), codebook, 14)\n",
    "print(encoded_data.shape)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the distance look-up table to reduce computational time when calculating distance between vectors in searching\n",
    "# table has dimensions of (#clusters, #subspaces)\n",
    "def generate_distance_table(query, codebook, no_of_subspaces, no_of_clusters):\n",
    "    supspaces = get_subspaces(query, no_of_subspaces)\n",
    "    distance_table = np.zeros((no_of_clusters, no_of_subspaces))\n",
    "    # for each cluster (centroid) calculate squared euclidean distance between the subspace and the codebook for this supspace\n",
    "    for i in range(0, no_of_subspaces):\n",
    "        diff = codebook[i] - supspaces[i] # difference between supspace and its codebook\n",
    "        diff = diff ** 2\n",
    "        # sum differences to get the squared euclidean distance\n",
    "        supspace_distance = np.array(np.sum(diff, axis=1)) # dimensions: (#clusters, )\n",
    "        distance_table[:, i] = supspace_distance\n",
    "    return distance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 14)\n",
      "[[0.67878452 0.59505981 0.64504818 0.89481125 0.50392144 0.32806341\n",
      "  0.40926604 0.99054716 0.97501892 1.18705852 0.59437548 0.68023213\n",
      "  0.72089492 0.46316842]\n",
      " [0.24270807 1.17814643 0.89565408 0.16513137 0.62189285 0.45960578\n",
      "  1.05891837 0.97359862 0.30914343 0.22023374 0.46513622 0.47636488\n",
      "  0.66729672 0.71338093]\n",
      " [0.55494079 1.19390914 0.76376431 0.44669976 0.52579976 0.39419427\n",
      "  0.2138692  0.92757811 0.52745294 0.88960739 0.46839198 0.20529314\n",
      "  0.22340551 0.68220798]\n",
      " [0.7302112  0.49789198 0.27632803 0.70812285 1.09626042 0.07124777\n",
      "  0.39408664 0.22501026 0.62419868 0.3451618  0.33065289 0.95866703\n",
      "  0.69667893 0.64806217]\n",
      " [0.17331009 0.61482626 0.85469103 0.43238939 0.04702107 0.22704674\n",
      "  0.48050084 0.43634403 0.40440703 0.78864616 0.39099174 0.5347268\n",
      "  0.31353926 0.55944688]\n",
      " [0.63852748 0.80655461 0.70126415 0.62695804 0.53620534 0.70739315\n",
      "  0.65794761 0.61203385 1.13758676 0.60560183 0.17407295 0.35972395\n",
      "  1.15750399 0.69648638]\n",
      " [0.40273482 0.35812558 0.78405627 0.52713815 0.76905624 0.36422956\n",
      "  0.99934715 0.43991885 0.47600381 0.80544404 0.07864362 0.85320262\n",
      "  0.70472567 0.05401581]\n",
      " [0.33828382 1.21253585 0.12446094 0.42927403 0.67354397 0.24852945\n",
      "  0.66986238 1.0207863  0.61930346 0.6923854  0.66174274 0.74235985\n",
      "  1.05101848 0.93238921]]\n"
     ]
    }
   ],
   "source": [
    "distance_table = generate_distance_table([0.08925092, 0.773956, 0.6545715, 0.43887842, 0.43301523, 0.8585979, 0.085945606, 0.697368, 0.20146948, 0.094177306, 0.52647895, 0.9756223, 0.73575234, 0.7611397, 0.71747726, 0.78606427, 0.51322657, 0.12811363, 0.8397482, 0.45038593, 0.5003519, 0.370798, 0.1825496, 0.92676497, 0.78156745, 0.6438651, 0.40241432, 0.8227616, 0.5454291, 0.44341415, 0.45045954, 0.22723871, 0.092135906, 0.55458474, 0.8878898, 0.0638172, 0.85829127, 0.8276311, 0.27675968, 0.6316644, 0.16522902, 0.7580877, 0.70052296, 0.35452592, 0.06791997, 0.970698, 0.44568747, 0.89312106, 0.677919, 0.7783835, 0.75989944, 0.19463867, 0.36390603, 0.466721, 0.49779153, 0.04380375, 0.54656947, 0.15428948, 0.7433759, 0.6830489, 0.9225278, 0.7447621, 0.36664265, 0.9675097, 0.41085035, 0.32582533, 0.90553576, 0.37045968, 0.07634318, 0.4695558], codebook, no_of_subspaces, no_of_clusters)\n",
    "print(distance_table.shape)\n",
    "print(distance_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query a vector to get k closest vectors\n",
    "def search(encoded_data, distance_table, k, db : VecDB):\n",
    "    distances = []\n",
    "    # for each encoded vector in our database\n",
    "    for code in encoded_data: \n",
    "        distance = 0\n",
    "        i = 0\n",
    "        # for each centroid in this vector\n",
    "        for centroid in code: \n",
    "            # get the distance to this centroid from the distance table and sum distances up\n",
    "            distance += distance_table[centroid][i]\n",
    "            i += 1\n",
    "        distances.append(distance)\n",
    "\n",
    "    # get the indices of k vectors with smallest distances with the query vector\n",
    "    indices = np.argsort(distances)[:k]\n",
    "    results = []\n",
    "    # get those vectors from the database\n",
    "    for index in indices:\n",
    "        results.append(db.get_one_row(index))\n",
    "    return np.array(results), indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 773 484 401 577]\n",
      "[[8.92509222e-02 7.73956001e-01 6.54571474e-01 4.38878417e-01\n",
      "  4.33015227e-01 8.58597875e-01 8.59456062e-02 6.97368026e-01\n",
      "  2.01469481e-01 9.41773057e-02 5.26478946e-01 9.75622296e-01\n",
      "  7.35752344e-01 7.61139691e-01 7.17477262e-01 7.86064267e-01\n",
      "  5.13226569e-01 1.28113627e-01 8.39748204e-01 4.50385928e-01\n",
      "  5.00351906e-01 3.70797992e-01 1.82549596e-01 9.26764965e-01\n",
      "  7.81567454e-01 6.43865108e-01 4.02414322e-01 8.22761595e-01\n",
      "  5.45429111e-01 4.43414152e-01 4.50459540e-01 2.27238715e-01\n",
      "  9.21359062e-02 5.54584742e-01 8.87889802e-01 6.38172030e-02\n",
      "  8.58291268e-01 8.27631116e-01 2.76759684e-01 6.31664395e-01\n",
      "  1.65229023e-01 7.58087695e-01 7.00522959e-01 3.54525924e-01\n",
      "  6.79199696e-02 9.70697999e-01 4.45687473e-01 8.93121064e-01\n",
      "  6.77918971e-01 7.78383493e-01 7.59899437e-01 1.94638669e-01\n",
      "  3.63906026e-01 4.66720998e-01 4.97791529e-01 4.38037515e-02\n",
      "  5.46569467e-01 1.54289484e-01 7.43375897e-01 6.83048904e-01\n",
      "  9.22527790e-01 7.44762123e-01 3.66642654e-01 9.67509687e-01\n",
      "  4.10850346e-01 3.25825334e-01 9.05535758e-01 3.70459676e-01\n",
      "  7.63431787e-02 4.69555795e-01]\n",
      " [4.76332307e-02 1.11022890e-01 5.44423163e-01 2.49027014e-02\n",
      "  7.23855913e-01 3.30868363e-02 4.23644245e-01 7.97642350e-01\n",
      "  4.67882454e-01 6.74938619e-01 3.33825767e-01 7.93490112e-01\n",
      "  4.26698744e-01 7.52947807e-01 9.52158451e-01 3.80975306e-01\n",
      "  2.31969357e-01 9.33018506e-01 6.80887759e-01 8.77945542e-01\n",
      "  3.78388047e-01 3.48351598e-01 1.24054730e-01 7.72940993e-01\n",
      "  8.44167888e-01 8.19658160e-01 2.91173160e-01 4.88464355e-01\n",
      "  4.93152142e-01 1.20418906e-01 1.63793564e-04 3.34056795e-01\n",
      "  5.10320663e-01 9.88811255e-01 8.73785019e-01 7.15935349e-01\n",
      "  9.62756991e-01 7.74710834e-01 5.26246190e-01 9.11924303e-01\n",
      "  9.19895053e-01 2.02762842e-01 2.82639325e-01 9.68403995e-01\n",
      "  5.70839643e-03 5.18141985e-01 3.82813454e-01 7.44678497e-01\n",
      "  9.58263874e-01 3.18210304e-01 2.20428944e-01 3.29406917e-01\n",
      "  7.15627789e-01 3.59599710e-01 6.42393172e-01 3.48058879e-01\n",
      "  7.40431488e-01 6.25031590e-02 3.42614949e-01 3.09574306e-01\n",
      "  5.97914100e-01 6.47380710e-01 7.27137744e-01 9.01972890e-01\n",
      "  7.96281219e-01 4.16653156e-02 6.77639782e-01 1.66283250e-02\n",
      "  4.13576782e-01 5.92399061e-01]\n",
      " [4.34625566e-01 8.58965397e-01 7.38604665e-02 5.90003133e-01\n",
      "  5.40621936e-01 2.22932518e-01 3.44093978e-01 9.77743149e-01\n",
      "  5.95636189e-01 9.39734221e-01 4.71319079e-01 8.45725775e-01\n",
      "  6.19840443e-01 9.11596119e-01 3.26746702e-01 3.82141709e-01\n",
      "  4.04383540e-02 2.27804840e-01 1.38509512e-01 1.82903826e-01\n",
      "  3.08380008e-01 8.73759925e-01 3.78533185e-01 8.26631308e-01\n",
      "  8.14667702e-01 9.80938375e-01 5.08620739e-01 8.48252058e-01\n",
      "  4.19426560e-01 6.32365882e-01 8.10927272e-01 1.42281711e-01\n",
      "  5.75255156e-02 1.64847493e-01 7.21109629e-01 4.73699510e-01\n",
      "  2.80000091e-01 7.67795503e-01 1.50854588e-02 1.73275352e-01\n",
      "  4.69842613e-01 9.15517449e-01 7.48996377e-01 6.83790684e-01\n",
      "  7.10878193e-01 3.12309086e-01 4.47861552e-01 8.85759592e-01\n",
      "  7.29579806e-01 5.98630309e-01 8.29221606e-02 7.33158469e-01\n",
      "  3.65707040e-01 3.85442197e-01 6.73904181e-01 3.93550515e-01\n",
      "  5.72890460e-01 1.26175284e-02 1.85013115e-01 5.37901998e-01\n",
      "  9.57720160e-01 7.60796785e-01 4.17571127e-01 9.68824506e-01\n",
      "  2.75412798e-01 8.92226815e-01 4.03431118e-01 8.69910717e-02\n",
      "  2.47633457e-03 9.80520070e-01]\n",
      " [6.19897127e-01 6.86482131e-01 6.67591989e-01 9.11995947e-01\n",
      "  7.84913003e-01 3.04768622e-01 1.69548988e-01 8.45285892e-01\n",
      "  3.72538030e-01 3.11124206e-01 1.11089587e-01 5.51909387e-01\n",
      "  5.12102723e-01 8.28099847e-01 7.48629808e-01 7.23149598e-01\n",
      "  5.38480103e-01 8.62869620e-01 9.83304441e-01 8.14881146e-01\n",
      "  3.47982526e-01 2.76347220e-01 1.31738186e-03 9.92936671e-01\n",
      "  7.32650578e-01 9.36998427e-01 7.87641704e-01 4.30174589e-01\n",
      "  1.45030618e-01 4.72094417e-02 7.92113900e-01 3.03496659e-01\n",
      "  3.79292607e-01 8.36152494e-01 4.81291473e-01 9.50870395e-01\n",
      "  5.46604335e-01 8.31671953e-01 1.25930309e-01 3.96743178e-01\n",
      "  1.83106899e-01 5.65364957e-02 9.91647184e-01 5.17582834e-01\n",
      "  3.53691280e-01 3.76382470e-01 2.40924299e-01 1.22972369e-01\n",
      "  9.13368106e-01 1.05853319e-01 3.84688735e-01 1.53036833e-01\n",
      "  9.29613352e-01 2.05823660e-01 3.93970251e-01 7.53786385e-01\n",
      "  5.70241094e-01 3.81703436e-01 5.63682854e-01 4.36938107e-01\n",
      "  2.89312422e-01 5.98381281e-01 3.65264058e-01 9.60133433e-01\n",
      "  4.63178873e-01 7.56469011e-01 2.34434485e-01 6.45712554e-01\n",
      "  5.59481084e-01 7.43832111e-01]\n",
      " [2.12781727e-01 7.05739856e-01 6.07543528e-01 4.03037012e-01\n",
      "  5.65690994e-02 6.87682033e-02 3.59004080e-01 5.37454486e-01\n",
      "  9.96897757e-01 7.23455548e-01 4.85388637e-01 2.99159884e-01\n",
      "  1.68608129e-01 1.40751123e-01 7.18877912e-02 9.11841154e-01\n",
      "  1.58756971e-02 8.63749623e-01 5.83508193e-01 6.18434191e-01\n",
      "  9.58652794e-01 7.86607146e-01 1.47127032e-01 9.68805313e-01\n",
      "  1.76075637e-01 5.69258928e-01 6.40646696e-01 2.44181633e-01\n",
      "  6.30270302e-01 6.38811946e-01 9.79866266e-01 9.14593637e-01\n",
      "  3.99693370e-01 6.90148175e-01 8.20934713e-01 2.62403488e-02\n",
      "  6.84828341e-01 9.17132556e-01 1.20244563e-01 7.53675222e-01\n",
      "  6.03626966e-02 4.01830971e-01 8.19488585e-01 9.87491846e-01\n",
      "  7.27773607e-01 7.21679330e-01 2.59155631e-01 8.25441062e-01\n",
      "  6.58895791e-01 9.43166554e-01 6.02868557e-01 3.95784378e-02\n",
      "  5.10955513e-01 7.74419785e-01 7.87937820e-01 3.86346400e-01\n",
      "  1.71015739e-01 8.69075000e-01 8.23163211e-01 8.78895819e-01\n",
      "  6.70605719e-01 8.28618467e-01 4.02794898e-01 7.79200554e-01\n",
      "  4.88262713e-01 7.94282794e-01 1.46321237e-01 2.96552479e-01\n",
      "  2.14395702e-01 4.06528175e-01]]\n"
     ]
    }
   ],
   "source": [
    "results, indices = search(encoded_data, distance_table, 5, db)\n",
    "print(indices)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, no_of_clusters):\n",
    "    kmeans = KMeans(n_clusters=no_of_clusters, random_state=42)\n",
    "    kmeans.fit(training_data)\n",
    "    assignments = kmeans.labels_\n",
    "    cluster_to_ids : dict[int: list[int]]= {}\n",
    "    for i in range(0, no_of_clusters):\n",
    "        cluster_to_ids[i] = []\n",
    "    for i in range(0, len(assignments)):\n",
    "        cluster_to_ids[assignments[i]].append(i)\n",
    "    return kmeans, cluster_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 70)\n",
      "16\n",
      "30\n",
      "17\n",
      "29\n",
      "15\n",
      "8\n",
      "11\n",
      "19\n",
      "7\n",
      "7\n",
      "18\n",
      "19\n",
      "25\n",
      "9\n",
      "14\n",
      "18\n",
      "45\n",
      "40\n",
      "2\n",
      "28\n",
      "40\n",
      "23\n",
      "20\n",
      "25\n",
      "20\n",
      "22\n",
      "20\n",
      "15\n",
      "12\n",
      "28\n",
      "17\n",
      "29\n",
      "33\n",
      "12\n",
      "4\n",
      "20\n",
      "39\n",
      "18\n",
      "28\n",
      "27\n",
      "36\n",
      "15\n",
      "15\n",
      "7\n",
      "37\n",
      "11\n",
      "13\n",
      "16\n",
      "7\n",
      "14\n",
      "{0: [15, 65, 105, 137, 147, 148, 199, 374, 606, 676, 743, 756, 766, 807, 831, 909], 1: [22, 85, 95, 128, 129, 184, 208, 236, 267, 292, 294, 363, 401, 424, 455, 467, 483, 502, 597, 604, 628, 646, 739, 851, 900, 916, 927, 930, 932, 981], 2: [56, 337, 339, 406, 411, 443, 496, 518, 593, 688, 714, 754, 874, 915, 955, 986, 996], 3: [67, 71, 84, 185, 203, 273, 422, 447, 514, 569, 584, 592, 600, 601, 610, 632, 699, 727, 729, 732, 751, 832, 843, 852, 875, 918, 969, 978, 999], 4: [13, 42, 54, 167, 177, 181, 304, 487, 508, 764, 776, 779, 805, 811, 857], 5: [18, 122, 253, 331, 366, 470, 550, 724], 6: [268, 326, 419, 465, 513, 516, 546, 547, 778, 795, 879], 7: [37, 111, 142, 151, 204, 240, 287, 328, 580, 616, 668, 694, 753, 775, 783, 793, 924, 947, 948], 8: [113, 409, 428, 545, 682, 737, 854], 9: [103, 227, 454, 493, 501, 505, 897], 10: [62, 86, 110, 154, 187, 255, 258, 310, 449, 556, 645, 672, 718, 734, 771, 819, 903, 982], 11: [82, 91, 180, 183, 206, 211, 213, 336, 347, 453, 500, 522, 551, 608, 684, 687, 894, 944, 974], 12: [44, 49, 80, 172, 202, 214, 305, 306, 356, 372, 407, 438, 587, 622, 626, 679, 738, 752, 767, 787, 886, 972, 976, 984, 995], 13: [98, 228, 528, 537, 818, 828, 885, 899, 938], 14: [48, 75, 209, 247, 250, 271, 319, 448, 504, 582, 655, 791, 812, 917], 15: [81, 94, 118, 130, 234, 270, 436, 469, 636, 647, 706, 750, 824, 825, 850, 960, 983, 985], 16: [17, 43, 47, 99, 117, 121, 139, 164, 197, 218, 251, 252, 269, 275, 286, 313, 314, 351, 369, 392, 412, 414, 441, 456, 488, 590, 611, 637, 638, 639, 643, 700, 723, 741, 777, 833, 834, 836, 844, 864, 883, 912, 913, 958, 968], 17: [20, 21, 23, 32, 50, 87, 114, 116, 178, 194, 284, 308, 332, 335, 393, 405, 410, 433, 437, 442, 452, 468, 506, 512, 571, 583, 623, 649, 650, 670, 680, 762, 786, 821, 823, 863, 881, 926, 952, 959], 18: [266, 473], 19: [9, 63, 64, 78, 126, 144, 261, 311, 352, 418, 472, 509, 575, 596, 599, 702, 713, 742, 755, 765, 798, 799, 816, 876, 945, 951, 989, 994], 20: [0, 12, 27, 33, 109, 150, 201, 245, 262, 265, 280, 290, 345, 349, 391, 396, 423, 432, 484, 492, 499, 524, 536, 577, 588, 618, 653, 663, 717, 745, 768, 785, 838, 869, 902, 923, 977, 987, 988, 993], 21: [38, 138, 153, 173, 226, 231, 260, 315, 364, 385, 399, 471, 548, 585, 598, 612, 697, 710, 769, 788, 907, 908, 998], 22: [31, 46, 219, 229, 263, 295, 365, 408, 563, 594, 602, 633, 735, 780, 822, 855, 859, 877, 910, 934], 23: [70, 79, 196, 198, 288, 302, 324, 383, 440, 485, 511, 568, 573, 621, 651, 659, 678, 705, 806, 830, 870, 887, 904, 919, 965], 24: [2, 3, 4, 89, 107, 182, 193, 215, 283, 323, 376, 459, 520, 531, 539, 543, 578, 730, 789, 856], 25: [41, 92, 101, 106, 176, 200, 207, 216, 241, 353, 529, 549, 591, 605, 627, 658, 677, 683, 695, 841, 853, 895], 26: [100, 272, 300, 421, 435, 451, 490, 510, 525, 595, 716, 782, 792, 802, 847, 860, 880, 920, 950, 979], 27: [53, 123, 159, 221, 390, 460, 629, 696, 796, 797, 808, 848, 861, 888, 939], 28: [30, 220, 281, 384, 475, 538, 552, 555, 581, 619, 631, 963], 29: [36, 45, 83, 125, 131, 133, 134, 162, 256, 297, 325, 329, 334, 382, 413, 427, 466, 489, 507, 517, 519, 533, 609, 674, 709, 772, 784, 970], 30: [7, 19, 25, 39, 52, 57, 59, 317, 320, 474, 648, 707, 719, 758, 801, 922, 990], 31: [10, 88, 156, 165, 166, 171, 235, 244, 264, 276, 312, 321, 350, 359, 389, 417, 434, 486, 515, 532, 553, 614, 675, 744, 773, 781, 840, 872, 891], 32: [6, 28, 34, 60, 76, 97, 127, 136, 160, 169, 186, 239, 274, 343, 358, 375, 398, 429, 480, 497, 526, 534, 542, 579, 615, 686, 693, 733, 759, 770, 774, 929, 957], 33: [174, 223, 318, 482, 523, 544, 635, 666, 746, 817, 835, 865], 34: [40, 478, 845, 884], 35: [11, 61, 77, 108, 158, 191, 246, 254, 291, 309, 330, 397, 400, 426, 521, 613, 644, 662, 794, 815], 36: [14, 16, 58, 112, 135, 163, 188, 190, 232, 249, 285, 298, 327, 386, 388, 430, 461, 477, 498, 527, 557, 559, 603, 617, 620, 625, 641, 685, 691, 692, 703, 704, 720, 721, 726, 868, 933, 937, 966], 37: [152, 155, 371, 445, 476, 495, 560, 566, 607, 634, 715, 858, 901, 906, 925, 946, 962, 975], 38: [5, 68, 72, 102, 175, 189, 233, 237, 238, 357, 373, 458, 530, 554, 558, 589, 640, 712, 736, 749, 800, 814, 827, 866, 882, 943, 991, 992], 39: [143, 225, 257, 282, 293, 341, 355, 362, 368, 403, 444, 561, 567, 576, 652, 757, 790, 810, 813, 829, 837, 893, 896, 928, 935, 964, 980], 40: [24, 29, 69, 145, 157, 192, 212, 316, 322, 340, 354, 367, 381, 402, 415, 420, 425, 446, 450, 503, 570, 572, 642, 661, 701, 711, 725, 748, 803, 809, 820, 849, 862, 873, 892, 940], 41: [8, 124, 141, 222, 242, 303, 378, 404, 586, 747, 846, 878, 889, 890, 971], 42: [104, 161, 259, 333, 360, 462, 463, 562, 664, 681, 760, 826, 898, 931, 956], 43: [66, 195, 370, 481, 535, 669, 689], 44: [35, 73, 93, 115, 132, 149, 170, 248, 277, 279, 289, 296, 307, 348, 380, 416, 479, 494, 540, 574, 654, 656, 660, 665, 667, 671, 673, 740, 842, 905, 942, 953, 954, 961, 967, 973, 997], 45: [1, 96, 179, 205, 210, 344, 361, 379, 761, 867, 936], 46: [51, 55, 120, 146, 342, 377, 394, 395, 439, 464, 564, 624, 921], 47: [90, 119, 168, 243, 278, 301, 431, 491, 541, 565, 657, 698, 708, 722, 728, 804], 48: [26, 140, 217, 224, 911, 941, 949], 49: [74, 230, 299, 338, 346, 387, 457, 630, 690, 731, 763, 839, 871, 914]}\n"
     ]
    }
   ],
   "source": [
    "db = VecDB(db_size=1000)\n",
    "kmeans, cluster_to_ids = train(db.get_all_rows(), 50)\n",
    "print(kmeans.cluster_centers_.shape)\n",
    "for c, ids in cluster_to_ids.items():\n",
    "    print(len(ids))\n",
    "print(cluster_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    cosine_similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, estimator : KMeans, clusters_to_ids : dict[int, list[int]], db : VecDB, k : int):\n",
    "    kmeans.cluster_centers_ = kmeans.cluster_centers_.astype(float)\n",
    "    query = np.array(query).reshape((1,-1))\n",
    "    closest_clusters = estimator.predict(query)\n",
    "    distances = []\n",
    "    for closest_cluster in closest_clusters:\n",
    "        ids = clusters_to_ids[closest_cluster]\n",
    "        for id in ids:\n",
    "            vector = db.get_one_row(id)\n",
    "            cos = cos_similarity(query,vector)\n",
    "            distances.append((cos, id))\n",
    "    distances = sorted(distances, key= lambda x : x[0], reverse=True)\n",
    "    return [d[1] for d in distances[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 484, 423, 869, 396]\n"
     ]
    }
   ],
   "source": [
    "indices = search([0.08925092, 0.773956, 0.6545715, 0.43887842, 0.43301523, 0.8585979, 0.085945606, 0.697368, 0.20146948, 0.094177306, 0.52647895, 0.9756223, 0.73575234, 0.7611397, 0.71747726, 0.78606427, 0.51322657, 0.12811363, 0.8397482, 0.45038593, 0.5003519, 0.370798, 0.1825496, 0.92676497, 0.78156745, 0.6438651, 0.40241432, 0.8227616, 0.5454291, 0.44341415, 0.45045954, 0.22723871, 0.092135906, 0.55458474, 0.8878898, 0.0638172, 0.85829127, 0.8276311, 0.27675968, 0.6316644, 0.16522902, 0.7580877, 0.70052296, 0.35452592, 0.06791997, 0.970698, 0.44568747, 0.89312106, 0.677919, 0.7783835, 0.75989944, 0.19463867, 0.36390603, 0.466721, 0.49779153, 0.04380375, 0.54656947, 0.15428948, 0.7433759, 0.6830489, 0.9225278, 0.7447621, 0.36664265, 0.9675097, 0.41085035, 0.32582533, 0.90553576, 0.37045968, 0.07634318, 0.4695558], kmeans, cluster_to_ids, db, 5)\n",
    "print(indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
